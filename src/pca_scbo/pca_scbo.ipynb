{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-03T13:52:00.754393Z",
     "start_time": "2025-11-03T13:52:00.566479Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class SpeedReducerProblem:\n",
    "\n",
    "    def __init__(self, enforce_integer_teeth=True):\n",
    "        self.enforce_integer_teeth = enforce_integer_teeth\n",
    "        self.lb = np.array([2.6, 0.7, 17.0, 7.3, 7.3, 2.9, 5.0], dtype=np.float64)\n",
    "        self.ub = np.array([3.6, 0.8, 28.0, 8.3, 8.3, 3.9, 5.5], dtype=np.float64)\n",
    "        self.dim = 7\n",
    "        self.n_constraints = 11\n",
    "        self.f_star_ref = 2996.3482\n",
    "\n",
    "    def coerce_shape(self, X):\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        was_1d = (X.ndim == 1)\n",
    "        if was_1d:\n",
    "            X = X[None, :]\n",
    "        assert X.shape[-1] == 7, \"Expected last dimension to be 7.\"\n",
    "        return X, was_1d\n",
    "\n",
    "    def project_to_bounds(self, X):\n",
    "        return np.clip(X, self.lb, self.ub)\n",
    "\n",
    "    def evaluate(self, X):\n",
    "        X, was_1d = self.coerce_shape(X)\n",
    "        X = self.project_to_bounds(X).copy()\n",
    "        if self.enforce_integer_teeth:\n",
    "            X[:, 2] = np.rint(X[:, 2])\n",
    "        x1, x2, x3, x4, x5, x6, x7 = [X[:, i] for i in range(7)]\n",
    "        f = (\n",
    "                0.7854 * x1 * x2 ** 2 * (3.3333 * x3 ** 2 + 14.9334 * x3 - 43.0934)\n",
    "                - 1.508 * x1 * (x6 ** 2 + x7 ** 2)\n",
    "                + 7.4777 * (x6 ** 3 + x7 ** 3)\n",
    "                + 0.7854 * (x4 * x6 ** 2 + x5 * x7 ** 2)\n",
    "        )\n",
    "        g = np.empty((X.shape[0], 11), dtype=np.float64)\n",
    "        g[:, 0] = 27.0 / (x1 * x2 ** 2 * x3) - 1.0\n",
    "        g[:, 1] = 397.5 / (x1 * x2 ** 2 * x3 ** 2) - 1.0\n",
    "        g[:, 2] = 1.93 * x4 ** 3 / (x2 * x3 * x6 ** 4) - 1.0\n",
    "        g[:, 3] = 1.93 * x5 ** 3 / (x2 * x3 * x7 ** 4) - 1.0\n",
    "        g[:, 4] = np.sqrt((745.0 * x4 / (x2 * x3)) ** 2 + 16.9e6) / (0.1 * x6 ** 3) - 1100.0\n",
    "        g[:, 5] = np.sqrt((745.0 * x5 / (x2 * x3)) ** 2 + 157.5e6) / (0.1 * x7 ** 3) - 850.0\n",
    "        g[:, 6] = x2 * x3 - 40.0\n",
    "        g[:, 7] = 5.0 - x1 / x2\n",
    "        g[:, 8] = x1 / x2 - 12.0\n",
    "        g[:, 9] = 1.5 * x6 + 1.9 - x4\n",
    "        g[:, 10] = 1.1 * x7 + 1.9 - x5\n",
    "\n",
    "        if was_1d:\n",
    "            return f[0], g[0]\n",
    "        return f, g\n",
    "\n",
    "    def is_feasible(self, X):\n",
    "        _, g = self.evaluate(X)\n",
    "        return np.all(g <= 0.0, axis=-1)\n",
    "\n",
    "    def sample_lhs(self, n, rng=None):\n",
    "        if rng is None:\n",
    "            rng = np.random.default_rng()\n",
    "        d = self.dim\n",
    "        cut = np.linspace(0, 1, n + 1)\n",
    "        a = cut[:-1]\n",
    "        b = cut[1:]\n",
    "        u = rng.random((n, d))\n",
    "        pts = a[:, None] + (b - a)[:, None] * u\n",
    "        X = np.empty_like(pts)\n",
    "        for j in range(d):\n",
    "            X[:, j] = pts[rng.permutation(n), j]\n",
    "        X = self.lb + X * (self.ub - self.lb)\n",
    "        if self.enforce_integer_teeth:\n",
    "            X[:, 2] = np.rint(X[:, 2])\n",
    "        return X\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ExactGP(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # ARD RBF kernel is a good default for BO\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[-1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.mean_module(x)\n",
    "        cov  = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, cov)\n",
    "\n",
    "def fit_gp(train_x, train_y, iters=75, lr=0.1):\n",
    "    \"\"\"Fit a single GP with Adam on negative marginal log-likelihood.\"\"\"\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "    model = ExactGP(train_x, train_y, likelihood).to(device)\n",
    "\n",
    "    model.train(); likelihood.train()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for _ in range(iters):\n",
    "        opt.zero_grad()\n",
    "        out = model(train_x)\n",
    "        loss = -mll(out, train_y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    model.eval(); likelihood.eval()\n",
    "    return model, likelihood\n",
    "\n",
    "# ---- constrained Thompson sampling over candidate set ----\n",
    "@torch.no_grad()\n",
    "def constrained_thompson_step(model_f, models_c, lb, ub, n_candidates=1000, enforce_integer_teeth=True):\n",
    "    \"\"\"\n",
    "    Draw one next x via constrained TS:\n",
    "      1) sample f~posterior, c_i~posterior for i in constraints\n",
    "      2) map feasibility by c_i(x) <= 0\n",
    "      3) if any feasible: choose argmin f; else choose min total violation\n",
    "    \"\"\"\n",
    "    d = lb.shape[0]\n",
    "    # sample candidates uniformly in the box (we’ll add TR later)\n",
    "    cand = torch.rand(n_candidates, d, device=device) * (ub - lb) + lb\n",
    "\n",
    "    # If you want to enforce integer teeth in candidates as well:\n",
    "    if enforce_integer_teeth:\n",
    "        cand[:, 2] = torch.round(cand[:, 2])\n",
    "\n",
    "    # sample objective\n",
    "    f_dist = model_f(cand)\n",
    "    f_samp = f_dist.sample()  # (n_candidates,)\n",
    "\n",
    "    # sample constraints (stack as columns)\n",
    "    c_samps = []\n",
    "    for mc in models_c:\n",
    "        c_samps.append(mc(cand).sample().unsqueeze(-1))\n",
    "    C = torch.cat(c_samps, dim=-1)  # (n_candidates, G_or_g)\n",
    "\n",
    "    # feasibility test in ORIGINAL G-space:\n",
    "    # (for SCBO baseline, models_c already represent original constraints)\n",
    "    feas = torch.all(C <= 0.0, dim=-1)\n",
    "\n",
    "    if feas.any():\n",
    "        idx = torch.argmin(f_samp[feas])\n",
    "        best_idx = torch.nonzero(feas, as_tuple=False).squeeze(1)[idx]\n",
    "    else:\n",
    "        # sum of positive parts (total violation)\n",
    "        viol = torch.clamp(C, min=0.0).sum(dim=-1)\n",
    "        best_idx = torch.argmin(viol)\n",
    "\n",
    "    return cand[best_idx].detach()\n",
    "\n",
    "# ---- small utility to build training tensors from evaluated data ----\n",
    "def numpy_to_torch(X_np, y_np):\n",
    "    X = torch.as_tensor(X_np, dtype=torch.float32, device=device)\n",
    "    y = torch.as_tensor(y_np, dtype=torch.float32, device=device).flatten()\n",
    "    return X, y\n",
    "\n",
    "# ---- quick driver for ONE SCBO iteration (no trust-region yet) ----\n",
    "def scbo_build_models(X_hist, f_hist, C_hist):\n",
    "    \"\"\"\n",
    "    Build one objective GP and G constraint GPs in ORIGINAL space (SCBO baseline).\n",
    "    X_hist: (N,d)  f_hist: (N,)   C_hist: (N,G)\n",
    "    \"\"\"\n",
    "    X_t, f_t = numpy_to_torch(X_hist, f_hist)\n",
    "    model_f, lik_f = fit_gp(X_t, f_t)\n",
    "\n",
    "    models_c = []\n",
    "    G = C_hist.shape[1]\n",
    "    for i in range(G):\n",
    "        _, ci_t = numpy_to_torch(X_hist, C_hist[:, i:i+1])\n",
    "        m_i, _ = fit_gp(X_t, ci_t.squeeze(-1))\n",
    "        models_c.append(m_i)\n",
    "    return model_f, models_c\n",
    "\n",
    "def scbo_one_step(problem, X_hist, f_hist, C_hist, n_candidates=1000):\n",
    "    \"\"\"Fit GPs on history, do one constrained-TS pick, evaluate, append.\"\"\"\n",
    "    # bounds as torch\n",
    "    lb = torch.tensor(problem.lb, dtype=torch.float32, device=device)\n",
    "    ub = torch.tensor(problem.ub, dtype=torch.float32, device=device)\n",
    "\n",
    "    # build models\n",
    "    model_f, models_c = scbo_build_models(X_hist, f_hist, C_hist)\n",
    "\n",
    "    # pick next x\n",
    "    x_next_t = constrained_thompson_step(\n",
    "        model_f, models_c, lb, ub,\n",
    "        n_candidates=n_candidates,\n",
    "        enforce_integer_teeth=problem.enforce_integer_teeth\n",
    "    )\n",
    "    x_next = x_next_t.cpu().numpy()\n",
    "\n",
    "    # evaluate true f,g\n",
    "    f_next, g_next = problem.evaluate(x_next)\n",
    "\n",
    "    # append to history\n",
    "    X_new = np.vstack([X_hist, x_next])\n",
    "    f_new = np.concatenate([f_hist, np.atleast_1d(f_next)])\n",
    "    C_new = np.vstack([C_hist, g_next])\n",
    "    return X_new, f_new, C_new, x_next, f_next, g_next\n"
   ],
   "id": "57dfb7a6964f7816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 4 — Trust region (lite) and an SCBO run loop\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class TrustRegion:\n",
    "    \"\"\"\n",
    "    Very small box trust region:\n",
    "      - centered at incumbent (best feasible if any, else least-violation)\n",
    "      - expands on 'success', shrinks on 'failure'\n",
    "    \"\"\"\n",
    "    def __init__(self, lb, ub, init_frac=0.6, min_frac=0.05, max_frac=1.0,\n",
    "                 grow=1.6, shrink=0.5, succ_tol=3, fail_tol=3, rng=None):\n",
    "        self.lb = lb.astype(np.float32)\n",
    "        self.ub = ub.astype(np.float32)\n",
    "        self.center = (self.lb + self.ub) / 2.0\n",
    "        self.frac = init_frac\n",
    "        self.min_frac = min_frac\n",
    "        self.max_frac = max_frac\n",
    "        self.grow = grow\n",
    "        self.shrink = shrink\n",
    "        self.succ_tol = succ_tol\n",
    "        self.fail_tol = fail_tol\n",
    "        self.succ = 0\n",
    "        self.fail = 0\n",
    "        self.rng = np.random.default_rng() if rng is None else rng\n",
    "\n",
    "    def set_center(self, x_c):\n",
    "        self.center = x_c.astype(np.float32)\n",
    "\n",
    "    def sample(self, n_cand):\n",
    "        halfspan = 0.5 * self.frac * (self.ub - self.lb)\n",
    "        low  = np.maximum(self.center - halfspan, self.lb)\n",
    "        high = np.minimum(self.center + halfspan, self.ub)\n",
    "        U = self.rng.random((n_cand, len(self.lb))).astype(np.float32)\n",
    "        return low + U * (high - low)\n",
    "\n",
    "    def step(self, success):\n",
    "        if success:\n",
    "            self.succ += 1; self.fail = 0\n",
    "            if self.succ >= self.succ_tol:\n",
    "                self.frac = min(self.max_frac, self.frac * self.grow)\n",
    "                self.succ = 0\n",
    "        else:\n",
    "            self.fail += 1; self.succ = 0\n",
    "            if self.fail >= self.fail_tol:\n",
    "                self.frac = max(self.min_frac, self.frac * self.shrink)\n",
    "                self.fail = 0\n",
    "\n",
    "def best_feasible_value(f_hist, C_hist):\n",
    "    feas = np.all(C_hist <= 0.0, axis=1)\n",
    "    return np.min(f_hist[feas]) if np.any(feas) else np.nan\n",
    "\n",
    "def least_violation_index(C_hist):\n",
    "    viol = np.clip(C_hist, 0.0, None).sum(axis=1)\n",
    "    return int(np.argmin(viol))\n",
    "\n",
    "def scbo_run(problem, n_init=20, iters=100, n_cand=1024, verbose=True):\n",
    "    \"\"\"\n",
    "    Full SCBO loop:\n",
    "      1) LHS DoE\n",
    "      2) repeat:\n",
    "         - fit GPs on f and each constraint (original space)\n",
    "         - sample candidates in trust region\n",
    "         - constrained Thompson pick\n",
    "         - evaluate, update TR, update histories\n",
    "    Returns histories for plotting.\n",
    "    \"\"\"\n",
    "    # 1) initial DoE\n",
    "    X = problem.sample_lhs(n_init)\n",
    "    f_vals = []\n",
    "    C_vals = []\n",
    "    for x in X:\n",
    "        f_i, g_i = problem.evaluate(x)\n",
    "        f_vals.append(f_i); C_vals.append(g_i)\n",
    "    f_vals = np.array(f_vals, dtype=np.float64)\n",
    "    C_vals = np.array(C_vals, dtype=np.float64)\n",
    "\n",
    "    # init TR center: incumbent (feasible best else least-violation)\n",
    "    feas = np.all(C_vals <= 0.0, axis=1)\n",
    "    if np.any(feas):\n",
    "        inc_idx = np.argmin(f_vals[feas])\n",
    "        inc = X[feas][inc_idx]\n",
    "    else:\n",
    "        inc = X[least_violation_index(C_vals)]\n",
    "    tr = TrustRegion(problem.lb, problem.ub)\n",
    "    tr.set_center(inc.astype(np.float32))\n",
    "\n",
    "    best_hist = []\n",
    "    for t in range(iters):\n",
    "        if verbose and (t % 10 == 0):\n",
    "            print(f\"SCBO iter {t+1}/{iters} | TR frac={tr.frac:.3f}\")\n",
    "\n",
    "        # ---- fit models on history\n",
    "        model_f, models_c = scbo_build_models(X, f_vals, C_vals)\n",
    "\n",
    "        # ---- sample candidates in TR (on device)\n",
    "        cand_np = tr.sample(n_cand)\n",
    "        cand_t = torch.tensor(cand_np, dtype=torch.float32, device=device)\n",
    "\n",
    "        # enforce integer teeth for candidates too (optional, keeps consistency)\n",
    "        if problem.enforce_integer_teeth:\n",
    "            cand_t[:, 2] = torch.round(cand_t[:, 2])\n",
    "\n",
    "        # ---- TS pick\n",
    "        lb_t = torch.tensor(problem.lb, dtype=torch.float32, device=device)\n",
    "        ub_t = torch.tensor(problem.ub, dtype=torch.float32, device=device)\n",
    "        with torch.no_grad():\n",
    "            f_dist = model_f(cand_t)\n",
    "            f_samp = f_dist.sample()\n",
    "            c_cols = []\n",
    "            for mc in models_c:\n",
    "                c_cols.append(mc(cand_t).sample().unsqueeze(-1))\n",
    "            C_samp = torch.cat(c_cols, dim=-1)\n",
    "            feas_mask = torch.all(C_samp <= 0.0, dim=-1)\n",
    "            if feas_mask.any():\n",
    "                idx = torch.argmin(f_samp[feas_mask])\n",
    "                best_idx = torch.nonzero(feas_mask, as_tuple=False).squeeze(1)[idx]\n",
    "            else:\n",
    "                viol = torch.clamp(C_samp, min=0.0).sum(dim=-1)\n",
    "                best_idx = torch.argmin(viol)\n",
    "            x_next = cand_t[best_idx].cpu().numpy()\n",
    "\n",
    "        # ---- evaluate true black box\n",
    "        f_next, g_next = problem.evaluate(x_next)\n",
    "\n",
    "        # ---- update histories\n",
    "        X = np.vstack([X, x_next])\n",
    "        f_vals = np.append(f_vals, f_next)\n",
    "        C_vals = np.vstack([C_vals, g_next])\n",
    "\n",
    "        # ---- update TR center and size\n",
    "        prev_best = best_feasible_value(f_vals[:-1], C_vals[:-1])\n",
    "        curr_best = best_feasible_value(f_vals, C_vals)\n",
    "        success = (not np.isnan(curr_best)) and (np.isnan(prev_best) or curr_best < prev_best - 1e-12)\n",
    "        tr.step(success)\n",
    "\n",
    "        feas = np.all(C_vals <= 0.0, axis=1)\n",
    "        if np.any(feas):\n",
    "            inc_idx = np.argmin(f_vals[feas])\n",
    "            inc = X[feas][inc_idx]\n",
    "        else:\n",
    "            inc = X[least_violation_index(C_vals)]\n",
    "        tr.set_center(inc.astype(np.float32))\n",
    "\n",
    "        best_hist.append(curr_best)\n",
    "\n",
    "    return {\n",
    "        \"X\": X, \"f\": f_vals, \"C\": C_vals,\n",
    "        \"best_hist\": np.array(best_hist, dtype=float),\n",
    "    }\n",
    "\n",
    "# Quick smoke test (optional):\n",
    "# prob = SpeedReducerProblem(enforce_integer_teeth=True)\n",
    "# out = scbo_run(prob, n_init=20, iters=10, n_cand=512, verbose=True)\n",
    "# print(\"last best feasible:\", out[\"best_hist\"][-1])\n"
   ],
   "id": "2c384fa89aeef0e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
